titulo,contenido,categoria
A Conflict Resolution Method in Context-Aware Computing,"The creation of various mobile devices speeded up the development of context-aware computing. Context-aware applications are able to adjust execution policies at any moment according to context information such as equipment's position, electric power, network bandwidth, and so on. In various context-aware systems, an important solution is to isolate executable codes in different context into a number of program segments and to select different execution policies according to the context in the process of operation, thus increasing the programming flexibility. However, the method can result in conflicts, making the system unable to select correct execution policy. This paper proposes a kind of algorithm designed to resolve conflicts. The algorithm calculates the selection center of each policy and the offset value of each conflicting policy under the current context environment. The algorithm will select execution policies through comparing offsets of policies, thus eliminating conflicts. To avoid the problem of policy thrashing resulting from frequent changes of context environment within a small scope, the algorithm modifies the calculate method of offset through the introduction of persistence coefficient. Experiments testify that the algorithm can effectively eliminate conflicts and well manifest the intention of policy definition, making policy selection more reasonable. Meanwhile the algorithm can avoid the thrashing of policy selection, providing more satisfaction to user.",Context-aware services;Pervasive computing;Application software;Mobile computing;Bandwidth;Environmental factors;Displays;Algorithm design and analysis;Testing;Temperature
Development of a mobile ecogenomic sensor,"Modern ocean microbial research utilizes advanced molecular analytical techniques, such as polymerase chain reaction (PCR), DNA and protein probe arrays, and nucleic acid sequencing (etc.). Applying or at least initiating these techniques at the point and time of sample collection can enhance their effectiveness. To that end, in-situ sample processing and real-time molecular detection schemes have been implemented using deployable autonomous systems that can be operated in diverse ocean environments from shallow coastal waters to the deep sea. Such devices have been termed “ecogenomic sensors.” The size of these instruments currently requires that they be moored in a fixed location or passively mobile, drifting at fixed depth and observing microbial communities in a moving frame of reference with ocean currents. With the highly dynamic motion of open water and microbial life, the next frontier of ocean microbial research requires the improved capability of an actively mobile asset. A mobile ecogenomic sensor encompasses a fully maneuverable vehicle with weeks of persistence, environmental data analysis, detection of physical and biological features, autonomous sampling and in situ analysis, and near-real-time data reporting. This system is now being developed by integrating three components: a compact molecular analytical instrument (the 3rd generation Environmental Sample Processor), a long-range autonomous underwater vehicle, and software algorithms for AUV-based feature detection and sampling. A summary of the system and its initial application is presented.",Instruments;Oceans;Valves;Media;Mobile communication;Laboratories;DNA;Autonomous underwater vehicle (AUV);ecogenomic sensor;harmful algae bloom;in situ instrumentation;microbe;PCR;sample collection
IEEE Draft Guide for Architectural Framework and Application of Federated Machine Learning,"Federated machine learning defines a machine learning framework that allows a collective model to be constructed from data that is distributed across repositories owned by different organizations or devices. A blueprint for data usage and model building across organizations and devices while meeting applicable privacy, security and regulatory requirements is provided in this guide. It defines the architectural framework and application guidelines for federated machine learning, including description and definition of federated machine learning; the categories federated machine learning and the application scenarios to which each category applies; performance evaluation of federated machine learning; and associated regulatory requirements.",IEEE Standards;Computer architecture;Machine learning;Metasearch;Privacy;Security;Performance evaluation;Security;Computational efficiency;computation efficiency;economic viability;federated machine learning (FML);IEEE 3652.1™;incentive mechanism;machine learning;model performance;privacy;privacy regulations;security
Unveiling the Potential of Machine Learning: Harnessing Machine Learning for Enhanced Coronary Heart Disease Detection and Intervention,"Coronary heart disease (CHD) remains a critical global health issue, necessitating effective predictive models to enhance early diagnosis and intervention. This study explores the application of various machine learning algorithms to CHD data to identify and predict the risk of developing the disease based on health indicators. We employed several algorithms, including Logistic Regression, Random Forest Classifier, Support Vector Machine (SVM), and Recurrent Neural Network (RNN), each with its unique strengths and limitations. The Logistic Regression model achieved an accuracy of approximately 86%, proving effective in binary classification tasks but revealing potential class imbalance issues. The Random Forest Classifier demonstrated robustness with an accuracy of around 85.24%, adeptly handling complex datasets. While specific accuracy metrics for the SVM were not detailed, it was noted for its classification capabilities. The RNN achieved an accuracy of approximately 85.96%, effectively capturing temporal dependencies within the data. Results indicate that although all models performed well, challenges such as class imbalance impacted performance metrics, especially in predicting CHD cases. This highlights the need for further refinement in predictive models to improve precision, recall, and F1-scores. Later research will examine the integration of advanced deep learning methodologies to enhance the precision and dependability of CHD forecasts.",Support vector machines;Heart;Logistic regression;Recurrent neural networks;Machine learning algorithms;Accuracy;Predictive models;Prediction algorithms;Random forests;Diseases;Coronary Heart Disease (CHD);Machine Learning Algorithms;Logistic Regression;Random Forest Classifier;Support Vector Machine (SVM);Recurrent Neural Network (RNN);Predictive Modelling in Healthcare
Unsupervised Machine Learning Methods for Artifact Removal in Electrodermal Activity,"Artifact detection and removal is a crucial step in all data preprocessing pipelines for physiological time series data, especially when collected outside of controlled experimental settings. The fact that such artifact is often readily identifiable by eye suggests that unsupervised machine learning algorithms may be a promising option that do not require manually labeled training datasets. Existing methods are often heuristic-based, not generalizable, or developed for controlled experimental settings with less artifact. In this study, we test the ability of three such unsupervised learning algorithms, isolation forests, 1-class support vector machine, and K-nearest neighbor distance, to remove heavy cautery-related artifact from electrodermal activity (EDA) data collected while six subjects underwent surgery. We first defined 12 features for each halfsecond window as inputs to the unsupervised learning methods. For each subject, we compared the best performing unsupervised learning method to four other existing methods for EDA artifact removal. For all six subjects, the unsupervised learning method was the only one successful at fully removing the artifact. This approach can easily be expanded to other modalities of physiological data in complex settings.Clinical Relevance— Robust artifact detection methods allow for the use of diverse physiological data even in complex clinical settings to inform diagnostic and therapeutic decisions.",Training;Support vector machines;Machine learning algorithms;Time series analysis;Pipelines;Surgery;Machine learning
Predicting Urban Land Cover Using Classification: A Machine Learning Approach,"The classification of urban land cover is a crucial step in comprehending the evolution of the urban environment and its effects. We are providing a comparative analysis of machine learning methods for classifying urban land cover using remote sensing data in this research. The study utilises the Urban Land Cover dataset which is obtained from the UCI Machine Learning Repository, which contains high-resolution images taken of urban areas. Also, comparison of several popular machine learning classification algorithms, such as Decision Tree classifier, Random Forest classifier, Support Vector Machine classifier (SVM/SVC), XGBoost classifier, K-Nearest Neighbors classifier (KNN) and Ridge classifier is done along with their accuracy scores. This comparison shows that the Random Forest algorithm outperforms the other machine learning algorithms with an overall accuracy of 91.38 % after removing the outliers and using Grid Search CV to tune the hyper-parameters.",Support vector machines;Machine learning algorithms;Forests;Shape;Urban areas;Land surface;Classification algorithms;Urban Land Cover Classification;Machine Learning Algorithms;Remote Sensing Data;Comparative Anal-ysis;MAUP;OBIA;Random Forest
Unlocking Stock Market Potential: Machine Learning Predictions for NIFTY50's Most Profitable Companies,"The use of machine learning (ML) to recognize the stock market trend as well as companies, which are expected to provide the most profit with-in NIFTY50 index is a focus area work in the past 5 years of historical data. We use many ML models (linear regression, decision trees, and neural networks) to predict stock price movements in order to decide which are the top 5 companies with the best return. In summary, according to our experiment the ML models can be good at predicting stock trends and are thus very useful for any investors. It demonstrates how deep learning and machine learning could be used to empower the levels of investment strategies with non-linear irregularities not captured by traditional models. The dictionary tells you what kind of processing has been performed on the data (such as missing value handling, normalization etc.), which keeps things more organized. We also use feature engineering techniques such as moving averages, relative strength index (RSI), and moving average convergence divergence (MACD) to improve the predictability of these models.",Neural networks;Linear regression;Machine learning;Companies;Predictive models;Market research;Indexes;Decision trees;Stock markets;Investment;Stock market prediction;machine learning;NIFTY50;linear regression;decision trees;neural networks
Unlocking Stock Market Potential: Machine Learning Predictions for NIFTY50's Most Profitable Companies,"The use of machine learning (ML) to recognize the stock market trend as well as companies, which are expected to provide the most profit with-in NIFTY50 index is a focus area work in the past 5 years of historical data. We use many ML models (linear regression, decision trees, and neural networks) to predict stock price movements in order to decide which are the top 5 companies with the best return. In summary, according to our experiment the ML models can be good at predicting stock trends and are thus very useful for any investors. It demonstrates how deep learning and machine learning could be used to empower the levels of investment strategies with non-linear irregularities not captured by traditional models. The dictionary tells you what kind of processing has been performed on the data (such as missing value handling, normalization etc.), which keeps things more organized. We also use feature engineering techniques such as moving averages, relative strength index (RSI), and moving average convergence divergence (MACD) to improve the predictability of these models.",Neural networks;Linear regression;Machine learning;Companies;Predictive models;Market research;Indexes;Decision trees;Stock markets;Investment;Stock market prediction;machine learning;NIFTY50;linear regression;decision trees;neural networks
Unsupervised Machine Learning Methods for Artifact Removal in Electrodermal Activity,"Artifact detection and removal is a crucial step in all data preprocessing pipelines for physiological time series data, especially when collected outside of controlled experimental settings. The fact that such artifact is often readily identifiable by eye suggests that unsupervised machine learning algorithms may be a promising option that do not require manually labeled training datasets. Existing methods are often heuristic-based, not generalizable, or developed for controlled experimental settings with less artifact. In this study, we test the ability of three such unsupervised learning algorithms, isolation forests, 1-class support vector machine, and K-nearest neighbor distance, to remove heavy cautery-related artifact from electrodermal activity (EDA) data collected while six subjects underwent surgery. We first defined 12 features for each halfsecond window as inputs to the unsupervised learning methods. For each subject, we compared the best performing unsupervised learning method to four other existing methods for EDA artifact removal. For all six subjects, the unsupervised learning method was the only one successful at fully removing the artifact. This approach can easily be expanded to other modalities of physiological data in complex settings.Clinical Relevance— Robust artifact detection methods allow for the use of diverse physiological data even in complex clinical settings to inform diagnostic and therapeutic decisions.",Training;Support vector machines;Machine learning algorithms;Time series analysis;Pipelines;Surgery;Machine learning
A Survey on Machine Learning Approaches and Its Techniques:,"With the data and information is available at a tremendous rate, there is a need for machine learning approaches. Machine learning, it analyses the study and constructs the algorithms by making prediction on data. It builds model from the inputs to make the decisions or predictions. Machine learning algorithms it assists in bridging the gap of understanding. In this literature we investigate different machine learning approaches and its techniques.",Machine learning algorithms;Supervised learning;Machine learning;Reinforcement learning;Semisupervised learning;Predictive models;Unsupervised learning;Machine learning;Supervised learning;Unsupervised learning;Semi-supervised learning;Reinforcement Learning.
Optimizing Marketing Strategies: Predicting Customer Personality using Advanced Machine Learning Models,"In the competition of modern marketing, it is highly important to foresee the correct personality profiles of customers because this may further improve the result of marketing campaigns. Therefore, in this research, three major models of machine learning are used, including Random Forest Classifier, Support Vector Machine (SVM), and Gradient Boosting Classifier, to discuss the challenges of predicting customer personalities. This study is helpful in finding unique customer segments and appropriate marketing strategies. These algorithms are valid to use for classifying customer personalities, and then determine the efficiency of it using the context also proves that through the more complex applications of such approaches, the efficacy of targeted marketing might be enhanced appropriately. Therefore, even more advanced deep learning techniques would be used at the next stage of research to further improve the forecasting accuracy and applicability in various marketing scenarios.",Support vector machines;Deep learning;Accuracy;Machine learning algorithms;Predictive models;Boosting;Prediction algorithms;Forecasting;Random forests;Optimization;Customer Personality Prediction;Customer Segmentation;Random Forest Classifier Support Vector Machine (SVM);Gradient Boosting Classifier;Marketing Strategy Optimization
A Machine Learning Approach to Predict Same-Day Discharge after Angiography Procedures,"Discharging patients from the hospital to care at home on the same day has been demonstrated to be as safe as overnight stays. The correct selection of patients who may undergo same-day discharge (SDD) is a significant challenge due to the large volume of variables that must be considered. This paper proposes a machine-learning approach to predict SDD after angiography procedures. Data from 3227 patients scheduled for angiography procedures, including information about geographical location, demographic characteristics, pre-existing diseases, and clinical procedure type, were used to train and test machine learning algorithms, such as logistic regression (LR), K-Nearest Neighbor, Naive Bayes, Multilayer Perceptron, and Support Vector Machine (SVM). The target was to predict patients with or without same-day discharge after they received an angiography procedure. Performance metrics, such as accuracy, precision, recall, F1-score, learning time, and inference time, were computed for each algorithm. The algorithms with the best performance were LR and SVM, with an F1-score of 0.800 and 0.806, respectively. LR had better behavior than SVM concerning learning and inference time.",Support vector machines;Machine learning algorithms;Angiography;Machine learning;Fault location;Nearest neighbor methods;Prediction algorithms;Inference algorithms;Physiology;Diseases;angiography procedures;machine learning;same-day discharge
"Multimodal Representation Learning: Advances, Trends and Challenges","Representation learning is the base and crucial for consequential tasks, such as classification, regression, and recognition. The goal of representation learning is to automatically learning good features with deep models. Multimodal representation learning is a special representation learning, which automatically learns good features from multiple modalities, and these modalities are not independent, there are correlations and associations among modalities. Furthermore, multimodal data are usually heterogeneous. Due to the characteristics, multimodal representation learning poses many difficulties: how to combine multimodal data from heterogeneous sources; how to jointly learning features from multimodal data; how to effectively describe the correlations and associations, etc. These difficulties triggered great interest of researchers along with the upsurge of deep learning, many deep multimodal learning methods have been proposed by different researchers. In this paper, we present an overview of deep multimodal learning, especially the approaches proposed within the last decades. We provide potential readers with advances, trends and challenges, which can be very helpful to researchers in the field of machine, especially for the ones engaging in the study of multimodal deep machine learning.",Multimodal;Representation learning;Machine learning;deep learning;Multimodal deep learning
Research on Edge Network Topology Optimization Based on Machine Learning,"Edge network topology optimization is an innovative structural design method that has made significant breakthroughs in the fields of aerospace and engineering. The use of data-driven network topology optimization has become the direction and trend of future structured topology research. At present, machine learning is fast, with greatly improved efficiency and accuracy; Machine learning can effectively solve the time-consuming problem of traditional implicit topology; And the prediction result of machine learning algorithm can be used as the Initial condition for optimizing the movable deformation component, so as to achieve the effect of rapid convergence. Network structure topology optimization can be widely applied in the field of science and technology, deepening scientific research, and promoting the continuous development of scientific productivity.",Productivity;Machine learning algorithms;Network topology;Deformation;Design methodology;Optimization methods;Machine learning;data-driven;Machine learning;Edge network;Network structure;algorithm
An overview of Machine Learning Technologies and their use in E-learning,"Thanks to new technologies, internet, connected objects we produce a phenomenal amount of data. Putting these data in context, organizing them to be able to perceive, understand and reflect them is very important. Traditionally, human have analyzed data. However, as the volume of data surpasses, human increasingly turn to automated systems that can imitate him. Those systems able to learn from both data and changes in data in order to solve problems are called machine learning. Artificial intelligence has a major impact on e-learning research and the machine learning based methods can be implemented to improve Technology Enhanced Learning Environments (TELE). This paper is an overview of the recent findings in this research field. At first, we introduce the key concepts related to machine learning. Then, we present some recent works using machine learning in e-learning context.",Machine learning;Machine learning algorithms;Support vector machines;Electronic learning;Computer science;Task analysis;E-learning;Technology Enhanced Learning Environments;Data;Learners' traces;Machine Learning;Deep Learning
Sentiment Analysis: A Machine Learning Perspective,"An essential part of natural language processing, sentiment analysis makes it possible to automatically extract sentiment from textual input. In this work, we examine how well different machine learning algorithms perform when used to analyze the sentiment of real-time Amazon reviews in the automobile niche. Leveraging a dataset comprising reviews from Amazon users, we employ SVM, KNN, Logistic Regression, and Random Forest algorithms to categorize text sentiment as positive, negative, or neutral. This work evaluates the performance of each algorithm in sentiment analysis tasks using strict evaluation standards and testing. Our findings provide insights into the effectiveness of machine learning approaches for analyzing sentiment in real-time reviews, offering valuable implications for businesses and organizations aiming to leverage customer feedback for decision-making and user experience enhancement.",Support vector machines;Sentiment analysis;Logistic regression;Machine learning algorithms;Reviews;Decision making;Signal processing algorithms;Real-time systems;Automobiles;Random forests;Random Forest;Logistic Regression;K-Nearest Neighbor (KNN);Support Vector Machine (SVM);NLP;Machine Learning (ML);Sentiment analysis;Reviewer text;Categorization;Predictive tasks
Semi-Supervised Machine Learning for Analyzing COVID-19 Related Twitter Data for Asian Hate Speech,"The COVID-19 pandemic left a lot of people sick, tired, and frustrated. Many people expressed their feelings on social media through comments and posts. Detecting hate speech on social media is important to help reduce the spread of racist comments. Machine learning algorithms can be used to classify hate speech. In our experiments, we implement semi-supervised machine learning algorithms to classify Twitter data. We used a count vectorizer as the feature and a support vector machine (SVM) classifier to classify COVID-19 related Twitter data while changing the amount of labeled data available. We found that self-training semi-supervised machine learning has similar effectiveness to supervised learning when there is significantly less training data available.",COVID-19;Support vector machines;Machine learning algorithms;Social networking (online);Supervised learning;Hate speech;Blogs;Asian hate;machine learning;self-training;semi-supervised;Twitter
Machine Learning Models for Cardiovascular Disease Events Prediction,"Cardiovascular diseases (CVDs) are among the most serious disorders leading to high mortality rates worldwide. CVDs can be diagnosed and prevented early by identifying risk biomarkers using statistical and machine learning (ML) models, In this work, we utilize clinical CVD risk factors and biochemical data using machine learning models such as Logistic Regression (LR), Support Vector Machine (SVM), Random Forest (RF), Naïve Bayes (NB), Extreme Grading Boosting (XGB) and Adaptive Boosting (AdaBoost) to predict death caused by CVD within ten years of follow-up. We used the cohort of the Ludwigshafen Risk and Cardiovascular Health (LURIC) study and 2943 patients were included in the analysis (484 annotated as dead due to CVD). We calculated the Accuracy (ACC), Precision, Recall, F1-Score, Specificity (SPE) and area under the receiver operating characteristic curve (AUC) of each model. The findings of the comparative analysis show that Logistic Regression has been proven to be the most reliable algorithm having accuracy 72.20 %. These results will be used in the TIMELY study to estimate the risk score and mortality of CVD in patients with 10-year risk.",Support vector machines;Machine learning algorithms;Biological system modeling;Computational modeling;Machine learning;Predictive models;Prediction algorithms;Machine Learning Models;Cardiovascular Disease;Risk Scores;10-Year Risk of CVD
A Class-Incremental Learning Method for Multi-Class Support Vector Machines in Text Classification,"To solve multi-class problems of support vector machines (SVM) more efficiently, a novel framework, which we call class-incremental learning (CIL), is proposed in this paper. CIL consists of two phases: incremental feature selection and incremental training, for updating the knowledge of old SVM classifiers in text classification when new classes are added to the system. CIL reuses the old models of the classifier and learns only one binary sub-classifier with an additional phase of feature selection when a new class comes. In the testing phase, current classifier is applied to the vectors' projections on the sub-spaces concerned. CIL can serve as a flexible approach for all binary classification algorithms in text classification. Our experiment shows that the CIL-based SVM was not only substantially faster in training time than the popular batch SVM learning methods such as 1-against-rest, 1-against-1 and divide-by-2 but also almost competed to the best performances in effectiveness of them",Learning systems;Support vector machines;Support vector machine classification;Text categorization;Machine learning;Information filtering;Information filters;Decision trees;Automation;Electronic mail;Machine learning;class-incremental learning;support vector machines;text classification;feature selection;Internet information filtering
A Survey on Skin Lesion Detection and Classification using Machine Learning,"The research explores how dermatologists use machine learning to quickly and accurately identify and classify skin injury. Conventional diagnosis techniques depend on visual examination, but are subjective and have different interpretations. The ability to analyze data and recognize patterns is a possible remedy for ML. The paper examines the current technology of machine learning, focusing on validation in the real world, and deals with data set variability. Although the research acknowledges the fruitfulness of deep learning (DL), the research emphasizes the benefits of traditional ML techniques regarding interpretation and processing performance. Methods for automating the analysis of skin lesions, such as feature engineering, rule-based techniques and traditional ML algorithms, have been studied. The study suggests using advanced transfer learning techniques, integrating genetic and clinical data, and refining the way artificial intelligence (AI) is explained in order to get over barriers. Intending to enhance the accessibility and correctness of skin lesion identification, the future requires collaboration between dermatology and machine learning to develop real-time diagnostic tools. By offering scalable solutions for rapid diagnosis of lesions and improved patient outcomes, this combination of medical expertise and ML capabilities has the power to revolutionize dermatology. The future of automated dermatological diagnosis is expected to be shaped by collaboration between machine learning experts and dermatologists, enabling more personalized treatment for patients.",Machine learning algorithms;Dermatology;Transfer learning;Collaboration;Machine learning;Genetics;Skin;skin lesion;machine learning;survey;deep learning;CNN
Machine learning-based distinction of left and right foot contacts in lower back inertial sensor gait data,"Digital gait measures derived from wearable inertial sensors have been shown to support the treatment of patients with motor impairments. From a technical perspective, the detection of left and right initial foot contacts (ICs) is essential for the computation of stride-by-stride outcome measures including gait asymmetry. However, in a majority of studies only one sensor close to the center of mass is used, complicating the assignment of detected ICs to the respective foot. Therefore, we developed an algorithm including supervised machine learning (ML) models for the robust classification of left and right ICs using multiple features from the gyroscope located at the lower back. The approach was tested on a data set including 40 participants (ten healthy controls, ten hemiparetic, ten Parkinson’s disease, and ten Huntington’s disease patients) and reached an accuracy of 96.3% for the overall data set and up to 100.0% for the Parkinson’s sub data set. These results were compared to a state-of-the-art algorithm. The ML approaches outperformed this traditional algorithm in all subgroups. Our study contributes to an improved classification of left and right ICs in inertial sensor signals recorded at the lower back and thus enables a reliable computation of clinically relevant mobility measures.",Machine learning algorithms;Inertial sensors;Computational modeling;Machine learning;Classification algorithms;Gyroscopes;Reliability
A Survey of Optimized Compiler Using Advanced Machine learning and Deep Learning Techniques,"Optimizing compilers is a difficult and time-consuming task, especially when done by hand. As far as we know, the compiler handles both translation and optimization. An efficient compiler system can become more automated and simple, as evidenced by recent studies using deep learning and machine learning approaches. Model training, prediction, optimization, and feature selection are handled by most machine learning and deep learning methods. In this case, choosing the optimal characteristics is necessary in order to use deep learning and machine learning techniques to enhance the optimization quality. This study examines various approaches that might be utilized to enhance and refine the quality of the chosen heuristics as well as the general quality of machine learning and deep learning models in order to boost the compiler's efficiency. The phase-ordering problem, the amount of iterative program evaluations, and the time needed to obtain the best forecast are only a few of the many subjects covered by these approaches.",Deep learning;Surveys;Training;Translation;Optimizing compilers;Artificial neural networks;Predictive models;Iterative methods;Optimization;Unsupervised learning;Phase-ordering;machine learning-ML;optimized compiler;deep learning;survey
Alignment-Free Sequence Comparison: A Systematic Survey From a Machine Learning Perspective,"The encounter of large amounts of biological sequence data generated during the last decades and the algorithmic and hardware improvements have offered the possibility to apply machine learning techniques in bioinformatics. While the machine learning community is aware of the necessity to rigorously distinguish data transformation from data comparison and adopt reasonable combinations thereof, this awareness is often lacking in the field of comparative sequence analysis. With realization of the disadvantages of alignments for sequence comparison, some typical applications use more and more so-called alignment-free approaches. In light of this development, we present a conceptual framework for alignment-free sequence comparison, which highlights the delineation of: 1) the sequence data transformation comprising of adequate mathematical sequence coding and feature generation, from 2) the subsequent (dis-)similarity evaluation of the transformed data by means of problem-specific but mathematically consistent proximity measures. We consider coding to be an information-loss free data transformation in order to get an appropriate representation, whereas feature generation is inevitably information-lossy with the intention to extract just the task-relevant information. This distinction sheds light on the plethora of methods available and assists in identifying suitable methods in machine learning and data analysis to compare the sequences under these premises.",Machine learning;Machine learning algorithms;Task analysis;Bioinformatics;Hardware;Data analysis;Systematics;Alignment-free sequence comparison;machine learning;systematization;proximity measures;data transformation;feature generation
Survey on Automated Machine Learning (AutoML) and Meta learning,"Automated Machine Learning is an area of research that has gained lots of research in the past few years. To build a high qualitymodel for Machine learning we need technical experts who have good knowledge in exploring various machines learning algorithm as well as to tune the hyperparameters efficiently. The size of data is increasing, it is observed that data scientist cannot address this challenging tasks due to lack of expertise and experience in the respective domain. So, there is a need to automate such crucial task inthe domain of machine learning. Metalearning is “learning to learn” like human expertise. This paper is initial survey of ongoing research in field of Meta Learning and AutoML.",Knowledge engineering;Deep learning;Machine learning algorithms;Costs;Machine learning;Artificial neural networks;Tools;AutoML;Deep Learning;Few shot learning;General AI;MetaLearning;Machine learning;Neural Networks;Meta-Reinforcement Learning;Meta-imitation Learning;One shot learning
Construction of Enterprise Business Management Analysis Framework in the Development of Artificial Intelligence,"In this era of rapid development, artificial intelligence has gradually entered our life, as a will be applied to the global technology, artificial intelligence in many fields have broad application prospects, artificial intelligence as the product of social development and technological innovation, has become a new round of scientific and technological innovation and the core driving force, is on the world economy, social progress and people’s life has had an extremely profound impact. The commercial application of artificial intelligence will change the internal operation and production and operation process of enterprises, and brings many challenges and reform opportunities for enterprise management. Article for the impact of artificial intelligence on the enterprise business management, analyze the application of enterprise business management and the impact of the technology application to the enterprise, and combined with some possible problems, in order to make artificial intelligence technology can be better applied in the enterprise management, put forward part of the corresponding solutions.",Technological innovation;Information science;Force;Production;Artificial intelligence;Business;Artificial intelligence;enterprise management
How do we move towards true artificial intelligence,"At present, the development of artificial intelligence technology has entered a new bottleneck period, and the algorithm dividend based on statistics has been exhausted. In the future, we should pay more attention to improving the efficient, intelligent collaboration among humans, machines, and the environment. This review first discusses the bottleneck problems encountered in the current artificial intelligence technology, then analyzes the essence of human intelligence and the differences, advantages, and disadvantages of the current machine intelligence and human intelligence. Based on this, it puts forward that the enhancement point of artificial intelligence technology is to enhance the efficient cooperation of the human-computer environment and states our solution, namely the deep situation awareness method based on human-computer integration technology. In the end, we put forward some thoughts about intelligence.",Smart cities;Human intelligence;Collaboration;Artificial intelligence;Machine intelligence;Artificial Intelligence;Human-computer Collaborative;Situation Awareness
Application and existing problems of computer network technology in the field of artificial intelligence,"With the development of science and technology, computer technology is more and more widely used in people's life. As a branch of computer technology, artificial intelligence technology is also gradually developing and expanding, affecting people's life. Nowadays, the processing ability shown by simple computer technology has gradually lagged behind the times. If you want more convenient data processing, artificial intelligence is an excellent solution. Agent technology in artificial intelligence makes artificial intelligence have stronger data processing ability and learning ability than computer technology, and can make decisions quickly according to data information. Artificial intelligence technology can promote automation and intelligence in various industries and improve the production efficiency of enterprises. Starting from the elaboration of artificial intelligence, this paper deeply explores the relationship between artificial intelligence and computer, analyzes the development status of artificial intelligence and computer, and puts forward the technical problems between artificial intelligence and computer, so as to provide reference for the further development of artificial intelligence.",Industries;Data analysis;Costs;Production;Learning (artificial intelligence);Planning;Data governance;artificial intelligence;Computer technology;Agent
A Review on Artificial Intelligence with Deep Human Reasoning,"Artificial Intelligence (AI) is a broad term that can be construed to mean a focusing computer programming and development that is designed to train machines and to perform task. Artificial intelligence can be used to test theories of reasoning like cognitive reasoning and consciousness. Research has been conducted on the development of machines with human behavior and cognitive characteristics that are related to consciousness. Artificial Intelligence and Reasoning that are dealt with, can necessarily solve problems related to mental health issues that humans find complex, but research on new interaction techniques and human for cooperation theories, technologies limited the issues and challenges facing the application of artificial reasoning. Here in this paper, the relation between artificial intelligence human reasoning that is also called as AI reasoning or artificial reasoning has been studied. Artificial intelligence impacts reasoning and how artificial reasoning can be used in day-to-day activities to regain our mental health. Moreover, this work focuses on problems that can be solved with AI Reasoning in trying to find the possible solutions.",Focusing;Mental health;Programming;Cognition;Artificial intelligence;Task analysis;Artificial reasoning;Artificial emotion;Cognitive reasoning;Artificial super intelligence;Linguistics
The Risks and Countermeasures of Accounting Artificial Intelligence,"Under the background of the information age, the development of science and technology has had an unprecedented situation, which makes people's lives have undergone tremendous changes, especially the development of artificial intelligence, which has increasingly penetrated into the field of accounting, which has attracted the attention of staff in various industries. The development of anything has two sides, while creating opportunities for us, but also bringing us certain challenges. This paper opens an analysis and discussion on the possible risks posed by accounting artificial intelligence. These include the staff risk of unemployment, and the information security risk analysis of the job content. In addition, corresponding solutions are put forward to help manage the transformation of accounting transformation and prevent the risks of artificial intelligence. The aim is to enhance our comprehensive thinking on artificial intelligence, improve the awareness of risk prevention in the application process of the accounting field, so that artificial intelligence technology has a good development space in the accounting field.",Industries;Information security;Learning (artificial intelligence);Information age;Risk analysis;Artificial intelligence;Unemployment;Accounting;artificial intelligence;risk;countermeasures
Research on the Application of Artificial Intelligence in Hotels,"At present, driven by new theories and technologies such as the Internet and big data, artificial intelligence is developing rapidly, and all walks of life are actively integrating with artificial intelligence technology to advance the development of the industry. This article takes the application of artificial intelligence in hotels as the research object, preliminaries analyzes the current status and existing problems of artificial intelligence development in the hotel industry, and proposes relevant solution strategies, hoping to provide certain ideas for the efficient application of artificial intelligence in hotels. To help hotel companies use artificial intelligence more rationally to enhance guest loyalty and satisfaction.",Industries;Databases;Learning (artificial intelligence);Companies;Big Data;Internet;Artificial intelligence;Information technology;Optimization;Faces;artificial intelligence;hotel
Analysis on the application of artificial intelligence in marketing,"With the continuous development of modern information technology, various new development technologies are gradually emerging. As an important development content of the discipline of computer science, artificial intelligence can simulate human activities through intelligent systems or intelligent machines, so as to extend people’s intelligence. Artificial intelligence has been widely used in all walks of life, combining artificial intelligence and marketing technology, can effectively innovate the traditional marketing methods, improve the overall development quality of marketing, through the analysis of artificial intelligence in the field of marketing application status, clear the advantages of artificial intelligence in the field of marketing, so as to better promote the overall quality of artificial intelligence in marketing development.",Computer science;Information science;Product design;Quality assessment;Artificial intelligence;Intelligent systems;Information technology;Artificial intelligence;Marketing
Application of artificial intelligence in computer network technology,"With the development of science and technology, artificial intelligence has been widely used in many fields, smart TVs, intelligent sweeping robots, intelligent voice, etc. are quiet trigger great changes in human society. At the same time, people are also exploring the integration and development of computer network technology and artificial intelligence, in order to use artificial intelligence advantages improve the accuracy and efficiency of data processing. The author first analyzes the concept of artificial intelligence, and then analyzes artificial intelligence in computer network technology in detail. The application of artificial intelligence in the field of computer is finally discussed.",Smart TV;Data processing;Computer networks;Artificial intelligence;Autonomous robots;artificial intelligence concept;Computer artificial intelligence technology;apply
"Applications, Risks and Countermeasures of Artificial Intelligence in Education","The application of artificial intelligence in education has greatly affected school management, teachers' teaching and students' learning, and has an important influence on the mechanism and mechanism of learning process. The concept of artificial intelligence is to simulate human intelligence by machine, thus completing specific roles and tasks, and has the characteristics of convenience, intelligence and interaction. It is mainly applied to computer vision, natural language processing, biometric recognition, speech recognition, human-computer interaction and other technologies in the field of education, which brings space for the development of architecture, medicine and chemistry. However, AI also brings about the risk of decisionmaking mistakes, career substitution, privacy leakage, information cocoon house and data bias. In order to avoid these risks effectively, this paper puts forward solutions from five perspectives: the state, product developers, educational managers, teachers and students, so as to correctly understand the relationship between artificial intelligence and education, explore the application mode of artificial intelligence in the field of education, and ensure the deep integration of artificial intelligence and education.",Training;Technological innovation;Education;Speech recognition;Learning (artificial intelligence);Resists;Natural language processing;Artificial intelligence;Educational application;Educational risk
Patient Attitude on the Application of Artificial Intelligence in Diabetes Care,"The integration of artificial intelligence (AI) into diabetes care holds the potential to transform patient management and improve outcomes, especially in Malaysia, where diabetes represents a major public health challenge. However, the adoption and effectiveness of AI in healthcare are significantly impacted by patient attitudes. This paper addresses the gap in understanding these attitudes. The primary goal of this study is to investigate the perspectives of diabetic patients on the use of AI applications and tools in diabetes care. This study also examined the patterns of acceptance and understanding of AI among diabetic patients. This study used qualitative methods using in-depth interviews with seventeen Malaysian diabetic patients in Hospital Tengku Ampuan Rahimah Klang (HTAR), Malaysia. The interview lasted two weeks, from August 8, 2023, to August 22, 2023. All interviews were audio-recorded and transcribed word-for-word. The transcribed content was then organized and coded using ATLAS.ti version 8. Thematic analysis was performed in accordance with established guidelines for data analysis. Three key themes emerged from participant interviews regarding the patients' attitudes toward AI application in diabetes care. These themes were perceived acceptability, perceived benefits of using AI tools, and perceived need. The majority of participants expressed their positive view of using AI tools. The findings of this study lay the groundwork for a theoretical framework aimed at understanding patients' stances on AI applications in diabetic care, emphasizing the health, technological, and social experiences that influence their perspectives on AI in this context.",Data analysis;Hospitals;Education;Transforms;Diabetes;Artificial intelligence;Interviews;Public healthcare;Guidelines;artificial intelligence;diabetic patients;attitudes;diabetes care;qualitative analysis
Analysis of the Impact of Artificial Intelligence on Electricity Consumption,"The in-depth development and widespread application of artificial intelligence technology will have significant impact on electricity demand. However, there are few comprehensive analyses. This article will analyze the direct and indirect impact respectively. For direct impact, artificial intelligence requires various data centers to provide huge computing and storage capabilities, which will increase the electricity demand of data centers; for indirect impact, artificial intelligence will also optimize the time and space distribution of electricity demand and deepen energy conservation and power saving in the whole society. Research shows that the development of artificial intelligence will increase the electricity consumption of data centers, and it is necessary to plan ahead for the infrastructure related to the electricity consumption of artificial intelligence; artificial intelligence plays an important role in promoting the development of demand response, and a largescale joint dispatch mechanism of electricity and computing power for the power market should be explored; data centers have a large space for energy conservation and carbon reduction, and a sound electricity price mechanism that comprehensively considers green electricity consumption and energy efficiency should be established to promote data centers to widely participate in green electricity transactions and actively reduce their own PUE.",Data centers;Electricity;Computational modeling;Energy conservation;Demand response;Power markets;Energy efficiency;Artificial intelligence;Carbon;Uninterruptible power systems;artificial intelligence;electricity demand;demand response;energy efficiency
Research on Artificial Intelligence Algorithm and Its Application in Games,"With the in-depth development of intelligent technology, game artificial intelligence (AI) has become the technical core of improving the playability of a game and the main selling point of game promotion, deepening the game experience realm. Modern computer games achieve the realism of games by integrating graphics, physics and artificial intelligence. It is difficult to define the meaning of realistic game experience, but generally speaking, it usually refers to the immersion of the game and the intelligence of non-player characters in the game. As the technical core of improving game playability and the selling point of many commercial games, game artificial intelligence gives players a way to interact with non-player characters in the game, and promotes the realm of game experience to a higher level. Based on this, this paper analyzes the history and present situation of artificial intelligence in game development, and puts forward the possible changes and impacts of artificial intelligence technology based on machine learning on game development in the future.",Graphics;Machine learning algorithms;Neural networks;Games;Machine learning;Learning (artificial intelligence);Tools;Artificial intelligence;Game experience;Machine learning
Artificial Intelligence Surpassing Human Intelligence: Factual or Hoax,"Artificial intelligence is one of the most trending topics in the field of Computer Science which aims to make machines and computers ‘smart’. There are multiple diverse technical and specialized research associated with it. Due to the accelerating rate of technological changes, artificial intelligence has taken over a lot of human jobs and is giving excellent results that are more efficient and effective, than humans. However, a lot of time there has been a concern about the following: will artificial intelligence surpass human intelligence in the near future? Are computers' ever accelerating abilities to outpace human jobs and skills a matter of concern? The different views and myths on the subject have made it even a more than just a topic of discussion. In this research paper, we will study the existing facts and literature to understand the true definitions of artificial intelligence (AI) and human intelligence (HI) by classifying each of its types separately and analyzing the extent of their full capabilities. Later, we will discuss the possibilities if AI eventually can replace human jobs in the market. Finally, we will synthesize and summarize results and findings of why artificial intelligence cannot surpass human intelligence completely in the future.",artificial intelligence;human intelligence;robotics;autonomous machines;computer science;artificial neural network;human brain
Decoding Justice: The Synergy of Artificial Intelligence and Machine Learning in the Legal Landscape,"The rapid integration of Artificial Intelligence (AI), Machine Learning (ML), and Internet of Things (IoT) technologies holds significant promise for enhancing human-centric applications, particularly in the domain of law enforcement. This paper explores the application of AI and ML in crime prevention and resource allocation, pivotal areas of concern for law enforcement agencies (LEAs) globally. By utilizing historical crime data, sensory inputs, and advanced analytics, this study contributes to the evolving discourse on smart policing and proactive crime strategies. Our objective is to facilitate the transformation of LEAs from primarily reactive entities into proactive crime preventers through the adoption of predictive analytics, facial recognition enhanced surveillance, and natural language processing for efficient data analysis. We emphasize that collaborative efforts with AI experts ensure the responsible use of technology, meticulously balancing security imperatives with privacy concerns.",Symbiosis;Technological innovation;Privacy;Law enforcement;Surveillance;Machine learning;Internet of Things;Security;Resource management;Artificial intelligence;Artificial intelligence;machine learning;law enforcement;smart policing;privacy
Application of artificial intelligence in computer network technology in the era of big data,"Today, with the progress of computer network technology, the advantages of artificial intelligence gradually began to show and become a new product under the development of the current era. At present, the strength of artificial intelligence technology lies in its data analysis and processing ability, because with the continuous development and progress of the society, the difficulty of processing data and information is becoming more and more complex for many years, and the processing ability of computers has begun to show shortcomings. The use of artificial intelligence can solve this problem well, and it can also put forward solutions according to the corresponding data problems, to timely deal with all kinds of data information. This paper mainly analyzes the application of artificial intelligence in computer network in the era of big data, and discusses the application and significance of artificial intelligence in big data.",Seminars;Data analysis;Big Data;Computer networks;Artificial intelligence;Information technology;Big data;artificial intelligence;computer network technology
Study on the Application Fields and Development Prospects of Artificial Intelligence,"Since the world entered the Internet age, various industries have developed rapidly, as has the industry of artificial intelligence. Moreover, there is a wide range of application areas in artificial intelligence, including industry, computer, education, and intelligent robots. With the rapid development of science and technology, it is believed that the artificial intelligence may develop towards the ""artificial intelligence +"" era and strong artificial intelligence, which will be comprehensively analyzed in terms of definition, development, and application areas. Especially the analysis of intellectual property rights is of reference significance to the intellectual property planning of domestic enterprises.",Industries;Education;Intellectual property;Production;Planning;Internet;Artificial intelligence;Artificial intelligence (AI);application field;future development
The Role of Artificial Intelligence (AI) in Transforming Biomedical Imaging: A Comprehensive Overview,"The integration of Artificial Intelligence (AI) in biomedical imaging heralds a transformative era in medical diagnostics and research. This comprehensive overview explores the multifaceted impact of AI on various imaging modalities, emphasizing its potential to revolutionize disease detection, characterization, and treatment planning. AI applications, particularly machine learning and deep learning, enhance the analysis of intricate imaging data, providing quicker and more accurate insights. This review delves into AI's role in automating diagnosis through the development of sophisticated algorithms, enabling faster and more precise identification of diseases across diverse medical imaging platforms. Furthermore, AI contributes to improving image quality, facilitating early detection of abnormalities, and enhancing decision support systems for clinicians. Beyond diagnosis, AI facilitates personalized medicine by tailoring treatment strategies based on individual patient data extracted from imaging. The ethical considerations and privacy implications of handling sensitive medical information are also discussed, ensuring a balanced perspective on the adoption of AI in healthcare. As AI continues to advance, this overview concludes with insights into future trends, challenges, and the collaborative synergy between technology, healthcare practitioners, and researchers, underscoring the ongoing evolution of biomedical imaging through artificial intelligence.",Privacy;Machine learning algorithms;Accuracy;Reviews;Precision medicine;Planning;Medical diagnosis;Artificial intelligence;Medical diagnostic imaging;Diseases;Artificial Intelligence;Biomedical Imaging;Deep Learning;Personalized Medicine;Medical Research
Block Design-Based Key Agreement for Group Data Sharing in Cloud Computing,"Data sharing in cloud computing enables multiple participants to freely share the group data, which improves the efficiency of work in cooperative environments and has widespread potential applications. However, how to ensure the security of data sharing within a group and how to efficiently share the outsourced data in a group manner are formidable challenges. Note that key agreement protocols have played a very important role in secure and efficient group data sharing in cloud computing. In this paper, by taking advantage of the symmetric balanced incomplete block design (SBIBD), we present a novel block design-based key agreement protocol that supports multiple participants, which can flexibly extend the number of participants in a cloud environment according to the structure of the block design. Based on the proposed group data sharing model, we present general formulas for generating the common conference key $\mathcal {K}$K for multiple participants. Note that by benefiting from the $(v,k + 1,1)$(v,k+1,1)-block design, the computational complexity of the proposed protocol linearly increases with the number of participants and the communication complexity is greatly reduced. In addition, the fault tolerance property of our protocol enables the group data sharing in cloud computing to withstand different key attacks, which is similar to Yi's protocol.",Protocols;Cloud computing;Fault tolerance;Fault tolerant systems;Data models;Cryptography;Key agreement protocol;symmetric balanced incomplete block design (SBIBD);data sharing;cloud computing
Research for current cloud computing and cloud security technology,"This paper introduces the concept, development, key features, applications of cloud computing. The difference to grid computing is discussed. Eight kinds of typical open source cloud computing projects are described, the security reference models of cloud services are given. Cloud computing security challenges and countermeasures are discussed in this paper.",Google;Cloud computing;Security;ISO;Clouds;Computational modeling;Reservoirs;cloud computing;cloud security;open source;security model
One Quantifiable Security Evaluation Model for Cloud Computing Platform,"Whatever one public cloud, private cloud or a mixed cloud, the users lack of effective security quantifiable evaluation methods to grasp the security situation of its own information infrastructure on the whole. This paper provides a quantifiable security evaluation system for different clouds that can be accessed by consistent API. The evaluation system includes security scanning engine, security recovery engine, security quantifiable evaluation model, visual display module and etc. The security evaluation model composes of a set of evaluation elements corresponding different fields, such as computing, storage, network, maintenance, application security and etc. Each element is assigned a three tuple on vulnerabilities, score and repair method. The system adopts “One vote vetoed” mechanism for one field to count its score and adds up the summary as the total score, and to create one security view. We implement the quantifiable evaluation for different cloud users based on our G-Cloud platform. It shows the dynamic security scanning score for one or multiple clouds with visual graphs and guided users to modify configuration, improve operation and repair vulnerabilities, so as to improve the security of their cloud resources.",Cloud computing;Maintenance engineering;Engines;Computational modeling;Visualization;Application security;cloud computing;security;quantifiable evaluation;security visualization;security view
Orchestration Based Hybrid or Multi Clouds and Interoperability Standardization,"In the present scenario, hybrid or multi-cloud environments are most suitable for Enterprises and Communities (like Government of India) for cloud bursting, disaster recovery, migration, and there is growing need for unified monitoring and management, however, it's challenging to setup a viable hybrid/multi-cloud environment. Currently, there are multiple solutions available in the market with limited success due to hidden drawbacks, for instance, vendor-lock-in, portability issues in migration, security threats and expensive in the long run and also, unfortunately, interoperability standardization is still work in progress. In this paper, we explore few hybrid/multi cloud use cases and demonstrate how these can be accomplished with our Federated Cloud Services Framework (middleware), which is built upon OpenStack [5], an open source cloud and by leveraging existing OpenStack functionalities.",Cloud computing;Monitoring;Aggregates;Resource management;Standardization;Computer architecture;Interoperability;Cloud Computing;Cost Efficiency;Interoperability;OpenStack;Vendor lock in;Hybrid Clouds;Federated Clouds
Comparison of Several Cloud Computing Platforms,"Cloud computing is the development of parallel computing, distributed computing and grid computing. It has been one of the most hot research topics. Now many corporations have involved in the cloud computing related techniques and many cloud computing platforms have been put forward. This is a favorable situation to study and application of cloud computing related techniques. Though interesting, there are also some problems for so many flatforms. For to a novice or user with little knowledge about cloud computing, it is still very hard to make a reasonable choice. What differences are there for different cloud computing platforms and what characteristics and advantages each has? To answer these problems, the characteristics, architectures and applications of several popular cloud computing platforms are analyzed and discussed in detail. From the comparison of these platforms, users can better understand the different cloud platforms and more reasonablely choose what they want.",Cloud computing;Distributed computing;Grid computing;Concurrent computing;Computer science;High performance computing;Parallel processing;Platform virtualization;Computer industry;Network servers;cloud computing;virtualization;utility computing;IaaS;PaaS;SaaS
"A ""No Data Center"" Solution to Cloud Computing","Current Cloud Computing is primarily based on proprietary data centers, where hundreds of thousands of dedicated servers are setup to host the cloud services. In addition to the huge number of dedicated servers deployed in data centers, there are billions of underutilized Personal Computers (PCs), usually used only for a few hours per day, owned by individuals and organizations worldwide. The vast untapped compute and storage capacities of the underutilized PCs can be consolidated as alternative cloud fabrics to provision broad cloud services, primarily infrastructure as a service. This approach, thus referred to as ""no data center"" approach, complements the data center based cloud provision model. In this paper, we present our opportunistic Cloud Computing system, called cuCloud, that runs on scavenged resources of underutilized PCs within an organization/community. Our system demonstrates that the ""no data center"" solution indeed works. Besides proving our concept, model, and philosophy, our experimental results are highly encouraging.",Cloud computing;Servers;Computational modeling;Random access memory;Organizations;Data models;Cloud Computing;IaaS;Volunteer Computing;No Data Center Solution;Credit Union Model;Credit Union Cloud
C-Cloud: A Cost-Efficient Reliable Cloud of Surplus Computing Resources,"This paper presents C-CLOUD, a democratic cloud infrastructure for renting computing resources includingnon-cloud resources (i.e. computing equipment not part of any cloud infrastructure, such as, PCs, laptops, enterprise servers and clusters). C-CLOUD enables enormous amount of surplus computing resources, in the range of hundreds of millions, to be rented out to cloud users. Such a sharing of resources allows resource owners to earn from idle resources, and cloud users to have a cost-efficient alternative to large cloud providers. Compared to existing approaches to sharing surplus resources, C-CLOUD has two key challenges: ensuring Service Level Agreement (SLA) and reliability of reservations made over heterogeneous resources, and providing appropriate mechanism to encourage sharing of resources. In this context, C-CLOUD introduces novel incentive mechanism that determines resourcerents parametrically based on their reliability and capability.",Resource management;Cloud computing;Context;Availability;Computer architecture;Cloud Computing;Reliability;Cost-efficiency
The KOALA Cloud Manager: Cloud Service Management the Easy Way,"The key advantages of cloud computing are flexibility, scalability (elasticity) and usability and these features originate in the combination of virtualization technologies with web services. However, in contrast to the elasticity and flexibility of cloud services the traditional management methods and tools seem inappropriate because they usually require local software installation with continuous updates and patches. Furthermore, the solutions are often proprietary and only conform to the cloud service offerings of specific service providers, making it difficult to work with cloud services of different providers. A vendor agnostic generic cloud based software service would bear many advantages in this area. This paper describes the design of a better management solution - the KOALA cloud management service - for cloud services and its implementation.",Cloud computing;Software;Browsers;Google;Graphical user interfaces;Mobile handsets;Cloud Computing;Service Management
Cloud Computing Infrastructure for Biological Echo-Systems,"The Biological applications such as Gene and Protein analysis integrate and analyze biological data for the research in many bioinformatics and other bio related fields. Such applications are used under many large scale scientific applications and help in computing, integrating data, execute the analysis, automate the process by using information retrieved by different tasks and computational procedures to assist the scientists in scientific discovery and data distribution. Grid based and/or web based scientific workflow tools are used for bioinformatics related complex research to make scientists' and researchers' work easier. On average, scientists spend about 80% of their time assembling data to prepare for analysis. This is due largely in part to the fact that many of these resources required for data processing must be gathered from an external source. The best of these resources, however, are scattered across the globe. They are hosted at universities, institutes, and laboratories throughout the world. To bring all of these resources together by hiding system, network, and application level heterogeneity issues are challenging.",Clouds;Biology;Computer architecture;Cloud computing;Software;Ecosystems;Hardware;Cloud Computing;Biologocal Cloud Systems
Cloud Computing for Emerging Mobile Cloud Apps,"The tutorial will begin with an explanation of the concepts behind cloud computing systems, cloud software architecture, the need for mobile cloud computing as an aspect of the app industry to deal with new mobile app design, network apps, app designing tools, and the motivation for migrating apps to cloud computing systems. The tutorial will review facts, goals and common architectures of mobile cloud computing systems, as well as introduce general mobile cloud services for app developers and marketers. This tutorial will highlight some of the major challenges and costs, and the role of mobile cloud computing architecture in the field of app design, as well as how the app-design industry has an opportunity to migrate to cloud computing systems with low investment. The tutorial will review privacy and security issues. It will describe major mobile cloud vendor services to illustrate how mobile cloud vendors can improve mobile app businesses. We will consider major cloud vendors, such as Microsoft Windows Azure, Amazon AWS and Google Cloud Platform. Finally, the tutorial will survey some of the cuttingedge practices in the field, and present some opportunities for future development.",Mobile communication;Cloud computing;Tutorials;Computer architecture;Industries;Conferences;Big data;Mobile App Design; Mobile Cloud Computing; Cloud Architecture; Mobile Security; Mobile Privacy
Connecting Fog and Cloud Computing,"There is a perfect storm of the use of cloud computing, and the growth of Internet of Things (IoT). IoT is about processing data that comes from devices in some way that's meaningful, and cloud computing is about leveraging data from centralized computing and storage. Growth rates of both can easily become unmanageable. We have some problems to solve. In addition, alternatives are being consider to placing everything in the public cloud because the public cloud, in some cases, no longer makes sense.",Cloud computing;Internet of Things;Standards;Sensors;Computer architecture;Edge computing;Databases;cloud computing;cloud tidbits;Internet of Things (IoT);OpenFog;fog computing
Cloud Bursting Scheduler for Cost Efficiency,"Clouds have been increasingly adopted due to primarily their elasticity and pay-as-you-go (PAYG) pricing. While many organizations outsource the entire ICT solution to public clouds like Amazon Web Services Elastic Compute Cloud (EC2), others consider occasional workload offloading (cloud bursting) due to various reasons including governance and security. In this paper, we present Cloud Bursting Scheduler (CBS), a new cloud bursting algorithm. CBS explicitly takes into account cost factors of private in-house system (or private cloud) and public cloud. In particular, CBS attempts to optimize the cost to performance ratio by offloading jobs to public cloud explicitly taking into account time-varying electricity rates with private clouds and the timeinvariant rental rate of many public clouds. Based on simulation results obtained using real workload traces, CBS saves costs of running workloads by 55% and 12% compared with costs of cloud sourcing and private cloud, respectively. It also improves resource utilization (to 89%) by judiciously (de)activating inhouse resources and dynamically provisioning cloud resources.",Cloud computing;Resource management;Program processors;Processor scheduling;Servers;Random access memory;Dynamic scheduling;Cloud computing;cloud bursting;cost efficiency;scheduling;energy efficiency
Hybrid Cloud Energy Management for Edge Computing,"Recently, many service providers or telecom operators are offering hybrid cloud services with edge computing to consumers, such as gaming, streaming, and manufacturing. However, the energy management of data centers is emphasized for enterprises in global ESG policy. Therefore, we propose the energy management architecture for hybrid cloud with edge computing which includes physical and virtual resources. In addition, we also propose the energy saving policy to improve resource utilization and cooling efficiency.",Cloud computing;Data centers;Cooling;Computer architecture;Telecommunications;Manufacturing;Resource management;Energy Management;Hybrid Cloud;Edge Computing
Cloud Migration: A Case Study of Migrating an Enterprise IT System to IaaS,"This case study illustrates the potential benefits and risks associated with the migration of an IT system in the oil & gas industry from an in-house data center to Amazon EC2 from a broad variety of stakeholder perspectives across the enterprise, thus transcending the typical, yet narrow, financial and technical analysis offered by providers. Our results show that the system infrastructure in the case study would have cost 37% less over 5 years on EC2, and using cloud computing could have potentially eliminated 21% of the support calls for this system. These findings seem significant enough to call for a migration of the system to the cloud but our stakeholder impact analysis revealed that there are significant risks associated with this. Whilst the benefits of using the cloud are attractive, we argue that it is important that enterprise decision-makers consider the overall organizational implications of the changes brought about with cloud computing to avoid implementing local optimizations at the cost of organization-wide performance.",Clouds;Companies;Cloud computing;Servers;Databases;Interviews;Maintenance engineering;Enterprise cloud computing;cloud migration;cloud adoption;IaaS;organizational change
SciCloud: Scientific Computing on the Cloud,"SciCloud is a project studying the scope of establishing private clouds at universities. With these clouds, researchers can efficiently use the already existing resources in solving computationally intensive scientific, mathematical, and academic problems. The project established a Eucalyptus based private cloud and developed several customized images that can be used in solving problems from mobile web services, distributed computing and bio-informatics domains. The poster demonstrates the SciCloud and reveals two applications that are benefiting from the setup along with our research scope and results in scientific computing.",Scientific computing;Cloud computing;Mobile computing;Web services;Grid computing;Distributed computing;Virtual machining;Computer networks;Project management;Clustering algorithms;Cloud computing;scientific computing;GRID;mobile web services;Mobile Host;Eucalyptus
Multi-Objective Resource Mapping and Allocation for Volunteer Cloud Computing,"Although Virtual Machine placement has been extensively researched in traditional Cloud Computing environments, it remains an open challenging problem for Volunteer Cloud Computing, which exhibits several divergent characteristics, including intermittent availability of nodes and unreliable infrastructure. In this paper, we model the Virtual Machine placement problem in Volunteer Cloud Computing as a bounded 0-1 multi-dimensional knapsack problem and develop three heuristic based algorithms to meet the objectives and constraints specific to Volunteer Cloud Computing. Empirical evidences on a real Volunteer Cloud Computing test-bed show the competitive performance results of these algorithms.",Cloud computing;Reliability;Mathematical model;Virtual machining;Resource management;Scheduling algorithms;Computational modeling;Volunteer Cloud Computing;VM Scheduling;cuCloud;NP-hard Problem;Knapsack Problem
Towards a Stakeholder-Oriented Taxonomical Approach for Secure Cloud Computing,"The emerging paradigm of cloud computing (CC) arises security risks that adversely impact its different stakeholders. The widespread deployment and service models of CC in addition to the wide variety of stakeholders make it difficult to guarantee privacy and security. This work-in-progress paper proposes a stakeholder-oriented taxonomical approach that determines the security and privacy issues for various CC models from a stakeholder's perspective. It recommends a comprehensive list of security and privacy attributes that are related to these issues. The goal is to provide stakeholders with the security issues associated with their interaction with the cloud. This will assist every stakeholder of a CC model in identifying the security and privacy concerns that are pertinent to them, based on the service and deployment model they use. This will help promote security and privacy among the stakeholders and refute their fears from utilizing this emerging technology.",Security;Privacy;Taxonomy;Cloud computing;Computational modeling;Government;Communities;cloud computing;cloud computing security;taxonomy;cloud stakeholders;cloud privacy;service models
IEEE Standard Adoption of ISO/IEC 15026-1--Systems and Software Engineering--Systems and Software Assurance--Part 1: Concepts and Vocabulary,Assurance-related terms are defined and an organized set of concepts and relationships to establish a basis for shared understanding across user communities for assurance are established in this adoption of ISO/IEC 15026-1. It provides information to users of the other parts of this International Standard including the combined use of multiple parts. The essential concept introduced by ISO/IEC 15026 is the statement of claims in an assurance caseand the support of those claims through argumentation and evidence. These claims are in the context of assurance for properties of systems and software within life cycle processes for the system or software product.Assurance for a service being operated and managed on an ongoing basis is not covered in this International Standard.,IEEE standards;Software engineering;Systems engineering and theory;Quality assurance;adoption;assurance;assurance case;claim;IEEE 15026-1(TM);integrity level;life cycle processes;reliability;software assurance;software engineering;system assurance;systems engineering
IEEE Approved Draft Standard for Software and Systems Engineering--Software Testing--Part 1: Concepts and Definitions,"The scope of this standard is the testing of software-intensive systems.Software is present in many of the products we use today and these products are getting more and more complex; for example a calendar on your PC, an electronic game, a mobile telephone, a car, or an aircraft. Software-intensive systems may describe a pure software system or may consist of a number of subsystems, such as hardware, network, documentation, data, data repository systems, license agreements, descriptions of manual processes, and of course, software.This standard supports testing across the entire software development lifecycle, from static testing of requirements, specifications and other documentation, unit or component testing that is typically carried out by developers, integration testing of program modules, system testing of integrated systems, and user acceptance testing that is usually carried out by end-users. It also supports testing during maintenance cycles that typically occur after release.",IEEE standards;Software engineering;Software testing
ISO/IEC/IEEE Draft International Standard - Systems and software engineering--Systems and software assurance -- Part 4: Assurance in the life cycle,This document provides guidance and recommendations for assurance of a selected claim about the system-of-interest by achieving the claim and showing the achievement. The guidance and recommendations are given in a System Assurance process view on top of ISO/IEC/IEEE 15288 and a Software Assurance process view on top of ISO/IEC/IEEE 12207.,IEEE Standards;IEC Standards;ISO Standards;Software assurance;Software engineering;Systems engineering and theory
SO/IEC/IEEE Draft Standard for Software and Systems Engineering--Software Testing--Part 1: Concepts and Definitions,"The scope of this standard is the testing of software-intensive systems.Software is present in many of the products we use today and these products are getting more and more complex; for example a calendar on your PC, an electronic game, a mobile telephone, a car, or an aircraft. Software-intensive systems may describe a pure software system or may consist of a number of subsystems, such as hardware, network, documentation, data, data repository systems, license agreements, descriptions of manual processes, and of course, software.This standard supports testing across the entire software development lifecycle, from static testing of requirements, specifications and other documentation, unit or component testing that is typically carried out by developers, integration testing of program modules, system testing of integrated systems, and user acceptance testing that is usually carried out by end-users. It also supports testing during maintenance cycles that typically occur after release.",IEEE standards;Software engineering
ISO/IEC/IEEE International Standard - Systems and software engineering--Life cycle management--Part 3: Guidelines for the application of ISO/IEC/IEEE 12207 (software life cycle processes),"ISO/IEC/IEEE 24748-3 provides guidance on the application of the software life cycle processes standard, ISO/IEC/IEEE 12207:2017. This document establishes guidance to implement a common framework for software life cycle processes, with well-defined terminology, that can be referenced by the software industry. This document provides guidance on defining, controlling, and improving software life cycle processes within an organization or a project. It recommends methods and approaches suitable for a variety of life cycle models. The guidance emphasizes the importance of establishing a strategy, planning, and the involvement of stakeholders, with the ultimate goal of achieving customer satisfaction. Its purpose is to help ensure consistency in system concepts and life cycle concepts, models, stages, processes, process application, key points of view, adaptation and use in various domains. This document concentrates on specific guidance for the Technical processes and how they can be effectively used during the software life cycle. It is intended to be useful in a variety of software life cycle situations, including the use of agile methods.",IEEE Standards;ISO Standards;IEC Standards;Software engineering;Systems engineering and theory;Product life cycle management;life cycle;life cycle process;software;system;project;stage;software engineering
IEEE Draft Standard for Software and Systems Engineering--Software Testing--Part 4: Test Techniques,"This part of ISO/IEC 29119 defines software testing techniques that can be used by any organization, project or smaller testing activity. The test techniques in this International Standard are used to derive the test cases executed as part of the dynamic testing process specified in part two of this standard. This International Standard is applicable to the testing in all software development lifecycle models. This document is intended for, but not limited to, testers, test managers, developers, project managers, particularly those responsible for governing, managing and implementing software testing.",IEEE standards;Software engineering;Software testing
ISO/IEC/IEEE Draft International Standard - Systems and software engineering--Systems and software assurance -- Part 4: Assurance in the life cycle,This document provides guidance and recommendations for assurance of a selected claim about the system-of-interest by achieving the claim and showing the achievement. The guidance and recommendations are given in a System Assurance process view on top of ISO/IEC/IEEE 15288 and a Software Assurance process view on top of ISO/IEC/IEEE 12207.,IEEE Standards;Software engineering;Systems engineering and theory;Product life cycle management;IEC Standards;ISO Standards
ISO/IEC/IEEE Approved Draft International Standard - Systems and Software Engineering-Life Cycle Management-Part 3: Guidelines for the Application of ISO/IEC/IEEE 12207 (Software Life Cycle Processes),"ISO/IEC/IEEE 24748-3 provides guidance on the application of the software life cycle processes standard, ISO/IEC/IEEE 12207:2017. This document establishes guidance to implement a common framework for software life cycle processes, with well-defined terminology, that can be referenced by the software industry. This document provides guidance on defining, controlling, and improving software life cycle processes within an organization or a project. It recommends methods and approaches suitable for a variety of life cycle models. The guidance emphasizes the importance of establishing a strategy, planning, and the involvement of stakeholders, with the ultimate goal of achieving customer satisfaction. Its purpose is to help ensure consistency in system concepts and life cycle concepts, models, stages, processes, process application, key points of view, adaptation and use in various domains. This document concentrates on specific guidance for the Technical processes and how they can be effectively used during the software life cycle. It is intended to be useful in a variety of software life cycle situations, including the use of agile methods.",IEEE Standards;ISO Standards;IEC Standards;Software engineering;Systems engineering and theory;Product life cycle management;life cycle;life cycle process;software;system;project;stage;software engineering
Automatic development tools in software engineering courses,"Discusses the role of automatic software development tools in graduate software engineering courses. The basic requirements for such tools, from the industry perspective, are presented, followed by the selection of tools meeting a comprehensive set of criteria in four process-related dimensions: internal, vertical, horizontal and diagonal. Typical software development projects for student teams used in the Software Engineering Program at the University of Central Florida are presented, involving the following four software tools: SES/workbench, ObjecTime Developer, iLogix Rhapsody and Gensym G2.",Software engineering;Software tools;Computer industry;Software performance;Software reusability;Computer languages;Software testing;Computer science;Programming profession;Communication industry
Draft International Standard Systems and software engineering -- Systems and software assurance -- Part 1: Concepts and vocabulary,This part of ISO/IEC defines assurance-related terms and establishes an organized set of concepts and relationships to establish a basis for shared understanding across user communities for assurance. It provides information to users of the other parts of this International Standard including the combined use of multiple parts. The essential concept introduced by ISO/IEC 15026 is the statement of claims in an assurance case and the support of those claims through argumentation and evidence. These claims are in the context of assurance for properties of systems and software within life cycle processes for the system or software product.Assurance for a service being operated and managed on an ongoing basis is not covered in ISO/IEC 15026.,IEEE standards;Software engineering;Systems engineering and theory;Quality assurance;Software quality
IEEE Draft International Standard - Systems and Software Engineering--Life Cycle Management--Part 5: Software Development Planning,"ISO/IEC/IEEE 24748 provides unified and consolidated guidance on the life cycle management of systems and software. It draws on key aspects of the former IEEE J-Std-016 Standard for information technology software Software life cycle processes Software development Acquirer-supplier agreement. The IEEE Standards Association has identified the need for a non-military standard to guide managers of software systems in software development planning.Taken together, the parts of ISO/IEC/IEEE 24748are intended to facilitate the joint usage of the process content of ISO/IEC/IEEE 12207 and ISO/IEC/IEEE 15288, Systems and software engineering System life cycle processes, which in turn may be used together with related standards such as for service management,and various lower-level process standards.",IEEE Standards;Software engineering;Product life cylce management;Software development;Systems engineering and theory
ISO/IEC/IEEE International Standard - Systems and software engineering--Systems and software assurance -- Part 4: Assurance in the life cycle,This document provides guidance and recommendations for assurance of a selected claim about the system-of-interest by achieving the claim and showing the achievement. The guidance and recommendations are given in a System Assurance process view on top of ISO/IEC/IEEE 15288 and a Software Assurance process view on top of ISO/IEC/IEEE 12207.,IEEE Standards;ISO Standards;IEC Standards;ISO Standards;Software engineering;System analysis and design;Product life cycle management
ISO/IEC/IEEE International Standard - Software engineering -- Guidelines for the application of ISO 9001:2015 to computer software,"This document provides guidance for organizations in the application of ISO 9001:2015 to the acquisition, supply, development, operation and maintenance of computer software and related support services. This document does not add to or otherwise change the requirements of ISO 9001:2015. The guidelines provided in this document are not intended to be used as assessment criteria in quality management system registration/certification. The application of this document is appropriate to software that is: part of a commercial contract with another organization, a product available for a market sector, used to support the processes of an organization, embedded in a hardware product, or related to software services. Some organizations may be involved in all the above activities; others may specialize in one area. Whatever the situation, the organization's quality management system should cover all aspects (software related and non-software related) of the business. This document identifies the issues that should be addressed and is independent of the technology, life cycle models, development processes, sequence of activities and organizational structure used by an organization. Additional guidance and frequent references to the ISO/IEC JTC 1/SC 7 software engineering standards are provided to assist in the application of ISO 9001:2015, in particular ISO/IEC/ IEEE 12207:2017.",IEEE Standards;ISO Standards;IEC Standards;Software engineering;Software quality;Software project management;Quality assessment;Quality Management; Quality Assurance; Quality Control; Quality Plan; Documentation; Software Quality; Project Management; Configuration Management; Release; Review; Defect; Customer Satisfaction; Testing; Verification; Validation; Management Review
What Pakistani Computer Science and Software Engineering Students Think about Software Testing?,"Software testing is one of the crucial supporting processes of the software life cycle. Unfortunately for the software industry, the role is stigmatized, partly due to misperception and partly due to treatment of the role. The present study aims to analyse the situation to explore what restricts computer science and software engineering students from taking up a testing career in the software industry. To conduct this study, we surveyed 88 Pakistani students taking computer science or software engineering degrees. The results showed that the present study supports previous work into the unpopularity of testing compared to other software life cycle roles. Furthermore, the findings of our study showed that the role of tester has become a social role, with as many social connotations as technical implications.",Computer science;Software testing;Industries;Engineering profession;Software;Software engineering;testing career;software engineering;software testing;human factors in software engineering;SQA
"Software engineering education in the era of outsourcing, distributed development, and open source software: challenges and opportunities","As software development becomes increasingly globally distributed, and more software functions are delegated to common open source software (OSS) and commercial off-the-shelf (COTS) components, practicing software engineers face significant challenges for which current software engineering curricula may leave them inadequately prepared. A new multi-faceted distributed development model is emerging that effectively commoditizes many development activities once considered integral to software engineering, while simultaneously requiring practitioners to apply engineering principles in new and often unfamiliar contexts. We discuss the challenges that software engineers face as a direct result of outsourcing and other distributed development approaches that are increasingly being utilized by industry, and some of the key ways we need to evolve software engineering curricula to address these challenges.",Software engineering;Outsourcing;Open source software;Design engineering;Programming;Computer architecture;Educational programs;Engineering management;Computer science education;Software reusability
IEEE/ISO/IEC Draft International Standard - Software and systems engineering--Software testing--Part 4: Test techniques,"The purpose of this part of ISO/IEC/IEEE 29119 is to provide an International Standard that defines software test design techniques (also known as test case design techniques or test methods) that can be used within the test design and implementation process that is defined in ISO/IEC/IEEE 29119-2. This part of ISO/IEC/IEEE 29119 does not describe a process for test design and implementation; instead, it describes a set of techniques that can be used within the test design and implementation process defined in ISO/IEC/IEEE 29119-2. The intent is to describe a series of techniques that have wide acceptance in the software testing industry. The test design techniques presented in this part of ISO/IEC/IEEE 29119 can be used to derive test cases that, when executed, generate evidence that test item requirements have been met or that defects are present in a test item (i.e. that requirements have not been met). Risk-based testing could be used to determine the set of techniques that are applicable in specific (risk-based testing is covered in ISO/IEC/IEEE 29119-1 and ISO/IEC/IEEE 29119-2).",IEEE Standards;ISO Standards;IEC Standards;Software engineering;Software testing;Systems engineering and theory
Software engineering education in South Africa,"The Software Engineer is a key member of the software development team. This paper explores the skills needed by a Software Engineer, and discusses how people are educated to acquire these skills. Based on recommendations from international organisations, the paper argues that Software Engineering is a professional engineering qualification. The relationship between engineering accreditation and the educational outcomes of a Software Engineering curriculum is discussed. Compared to other engineering disciplines, Software Engineering is very new. There is very little practical experience anywhere in the world of how Software Engineers should be educated. Many South African Universities are beginning to introduce computer-related engineering programmes. In the paper a case study of Software Engineering education is presented, focussing on South Africa. The difficulties associated with structuring and delivering these programmes in South Africa are described, and ideas are put forward for dealing with these difficulties.",Software;Software engineering;Accreditation;Knowledge engineering;Task analysis;Software measurement;Proposals;Software Engineering;Education;Engineering Curriculum Development
Machine learning-based algorithm selection for irregular three-dimensional packing in additive manufacturing,"In additive manufacturing (AM), a common problem is the efficient arrangement of arbitrary three-dimensional objects, subject to geometric constraints. This can be mapped to three-dimensional irregular packing (3DIP) problems, which have been systematically addressed by many academics and practitioners. This study demonstrates the utilisation of machine learning for algorithm selection to find efficient layout configurations during the design stage of the AM process. The choice of the most suitable approach to use, typically a packing algorithm, is not trivial, and depends on the non-obvious relationship between the characteristics of the instance in hand and the portfolio of algorithms available. The matching between problem features and algorithm performance forms the basis of the well-known algorithm selection problem. This study introduces the first empirical investigation of algorithm selection for 3DIP problems, conducting extensive experiments with hundreds of combinations of well-known supervised machine learning classifiers and different parameter settings to identify an initial state-of-the-art for this problem. We generate a comprehensive dataset, labelled with the performance of two of the most popular 3DIP algorithms, and analyse the features which can be used to support decision making when selecting a method to solve a 3DIP instance. Our results show that deploying machine learning-based algorithm selection methods are able to outperform the results obtained by the individual constituent packing algorithms applied independently, with the best algorithm selection method obtaining a 1.48% higher average build volume utilisation over the 2000 problem instances tested.",Heuristics
Predictive modeling of foreign exchange trading signals using machine learning techniques,"This study aimed to apply the algorithmic trading strategy on major foreign exchange pairs and compare the performances of machine learning-based and traditional momentum strategies with benchmark strategies. It differs from other studies in that it considered various cases, including different foreign exchange pairs, return methods, data frequency, and individual and integrated trading strategies. Ridge regression, KNN, RF, XGBoost, GBDT, ANN, LSTM, and GRU models were used for the machine learning-based strategy, while the MA cross strategy was employed for the momentum strategy. Backtests were performed on six major pairs from January 1, 2000, to June 30, 2023, and daily and intraday data were used. The Sharpe ratio was considered as a metric used to refer to economic significance and the independent t-test was used to determine statistical significance. The general findings of the study suggested that the currency market has become more efficient. The rise in efficiency is probably caused by the fact that more algorithms are being used in this market, and information spreads much faster. Instead of finding a trading strategy that works well in all major foreign exchange pairs, our study showed that it is possible to find an effective algorithmic trading strategy that generates a more effective trading signal in each specific case.",Machine learning
